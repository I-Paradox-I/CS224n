Pretraining *(by John Hewitt)*
[[slides](https://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture9-pretraining.pdf)]

Suggested Readings:

1. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)
2. [Contextual Word Representations: A Contextual Introduction](https://arxiv.org/abs/1902.06006.pdf)
3. [The Illustrated BERT, ELMo, and co.](http://jalammar.github.io/illustrated-bert/)
4. [Martin & Jurafsky Chapter on Transfer Learning](https://web.stanford.edu/~jurafsky/slp3/11.pdf)

Natural Language Generation *(by Xiang Lisa Li)*
[[slides](https://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture10-nlg.pdf)]

Suggested Readings:

1. [The Curious Case of Neural Text Degeneration](https://arxiv.org/abs/1904.09751.pdf)
2. [Get To The Point: Summarization with Pointer-Generator Networks](https://arxiv.org/abs/1704.04368.pdf)
3. [Hierarchical Neural Story Generation](https://arxiv.org/abs/1805.04833.pdf)
4. [How NOT To Evaluate Your Dialogue System](https://arxiv.org/abs/1603.08023.pdf)



Hugging Face Transformers Tutorial Session

[Colab](https://colab.research.google.com/drive/1pxc-ehTtnVM72-NViET_D2ZqOlpOi2LH?usp=sharing)



Assignment 5 **out**
[[code](https://web.stanford.edu/class/cs224n/assignments/a5.zip)]
[[handout](https://web.stanford.edu/class/cs224n/assignments/a5.pdf)]
[[latex template](https://web.stanford.edu/class/cs224n/assignments/a5_latex.zip)] [[colab](https://colab.research.google.com/drive/1VfdgyVFhcPG3ESWwdOCdOllEHnPliO3c?usp=sharing)]